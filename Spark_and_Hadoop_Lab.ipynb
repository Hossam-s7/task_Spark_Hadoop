{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e07b901-0b2e-42d7-81b4-761a500b34fe",
   "metadata": {},
   "source": [
    "1.  Read the CSV file provided into a Spark DataFrame.\n",
    "\n",
    "2.  Count the number of males and females who had their Cabin as null.\n",
    "\n",
    "3.  Find the average ages of passengers.\n",
    "\n",
    "4.  Fill in the missing age values with this average value.\n",
    "\n",
    "5.  Save the output to a CSV file in HDFS (depi_folder).\n",
    "\n",
    "6.  Count the total number of passengers who survived and those who did\n",
    "    not.\n",
    "\n",
    "7.  Find the top 5 most common embarkation ports among passengers.\n",
    "\n",
    "8.  Calculate the survival rate by passenger class (Pclass).\n",
    "\n",
    "9.  Determine the maximum, minimum, and average fare paid by passengers.\n",
    "\n",
    "10. Write a Spark job to count the number of passengers in each age\n",
    "    group (e.g., 0–18, 19–35, 36–60, 60+).\n",
    "\n",
    "11. Create a new directory in HDFS called titanic_lab and list its\n",
    "    contents.\n",
    "\n",
    "12. Upload the Titanic dataset from your local machine to the\n",
    "    titanic_lab directory in HDFS.\n",
    "\n",
    "13. Use chmod command to change the permissions of the Titanic dataset\n",
    "    file to 777 (full permissionsfor all)\n",
    "\n",
    "14. Use-cat to display the first 20 lines of the Titanic dataset stored\n",
    "    in HDFS.\n",
    "\n",
    "15- Move the processed output file from titanic_lab to a new directory\n",
    "in HDFS called titanic_results using hdfs dfs -mv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TitanicCSVExample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\n",
    "    r\"E:\\Material\\Skills Dynamix\\Spark,Hadoop_Task\\titanic.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df.show(10)\n",
    "\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225db169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males with null Cabin: 470\n",
      "Females with null Cabin: 217\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "null_cabin_df = df.filter(col(\"Cabin\").isNull())\n",
    "\n",
    "\n",
    "male_count = null_cabin_df.filter(col(\"gender\") == \"male\").count()\n",
    "female_count = null_cabin_df.filter(col(\"gender\") == \"female\").count()\n",
    "\n",
    "print(\"Males with null Cabin:\", male_count)\n",
    "print(\"Females with null Cabin:\", female_count)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Age of Passengers: 29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "\n",
    "avg_age = df.select(avg(\"Age\")).collect()[0][0]\n",
    "\n",
    "print(\"Average Age of Passengers:\", avg_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0ab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|gender|              Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "\n",
    "avg_age = df.select(avg(\"Age\")).collect()[0][0]\n",
    "\n",
    "\n",
    "df_filled = df.withColumn(\"Age\",\n",
    "               when(col(\"Age\").isNull(), avg_age).otherwise(col(\"Age\")))\n",
    "\n",
    "df_filled.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdb5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ر\n",
    "output_path = \"hdfs://localhost:9000/depi_folder/titanic_output\"\n",
    "\n",
    "df_filled.write \\\n",
    "    .option(\"header\", True) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e079118",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "import os\n",
    "import wget\n",
    "import tarfile\n",
    "\n",
    "\n",
    "HADOOP_URL = \"https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\"\n",
    "HADOOP_TAR = \"hadoop-3.3.6.tar.gz\"\n",
    "HADOOP_DIR = \"C:/hadoop\"  \n",
    "\n",
    "if not os.path.exists(HADOOP_TAR):\n",
    "    print(\"Downloading Hadoop...\")\n",
    "    wget.download(HADOOP_URL, HADOOP_TAR)\n",
    "else:\n",
    "    print(\"Hadoop archive already exists.\")\n",
    "\n",
    "if not os.path.exists(HADOOP_DIR):\n",
    "    print(\"\\nExtracting Hadoop...\")\n",
    "    with tarfile.open(HADOOP_TAR, \"r:gz\") as tar:\n",
    "        tar.extractall(path=os.path.dirname(HADOOP_DIR))\n",
    "    os.rename(\"hadoop-3.3.6\", HADOOP_DIR)\n",
    "else:\n",
    "    print(\"Hadoop directory already exists.\")\n",
    "\n",
    "os.environ[\"HADOOP_HOME\"] = HADOOP_DIR\n",
    "os.environ[\"PATH\"] += \";\" + os.path.join(HADOOP_DIR, \"bin\")\n",
    "\n",
    "print(\"\\n Hadoop downloaded and extracted at:\", HADOOP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3143d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r\"E:\\Material\\Skills Dynamix\\Spark,Hadoop_Task\\depi_folder\\titanic_output\"\n",
    "\n",
    "df_filled.write \\\n",
    "    .option(\"header\", True) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "\n",
    "survival_counts = df['Survived'].value_counts()\n",
    "\n",
    "print(survival_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d772e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 7.  Find the top 5 most common embarkation ports among passengers.\n",
    "top_ports = df['Embarked'].value_counts().head(5)\n",
    "print(top_ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f0bef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    0.629630\n",
      "2    0.472826\n",
      "3    0.242363\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 8.  Calculate the survival rate by passenger class (Pclass)\n",
    "survival_rate_by_class = df.groupby('Pclass')['Survived'].mean()\n",
    "print(survival_rate_by_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7fd739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max     512.329200\n",
      "min       0.000000\n",
      "mean     32.204208\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 9.  Determine the maximum, minimum, and average fare paid by passengers.\n",
    "fare_stats = df['Fare'].agg(['max', 'min', 'mean'])\n",
    "print(fare_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d8c70be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "0-18     113\n",
      "19-35    366\n",
      "36-60    209\n",
      "60+       26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 10. Write a Spark job to count the number of passengers in each age group (e.g., 0–18, 19–35, 36–60, 60+).\n",
    "from flask.views import F\n",
    "age_bins = [0, 18, 35, 60, float('inf')]\n",
    "age_labels = ['0-18', '19-35', '36-60', '60+']\n",
    "age_groups = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "age_group_counts = age_groups.value_counts().sort_index()\n",
    "print(age_group_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Create a new directory in HDFS called titanic_lab and list its\n",
    "#     contents.\n",
    "!hdfs dfs -mkdir -p /titanic_lab\n",
    "!hdfs dfs -ls /titanic_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Upload the Titanic dataset from your local machine to the\n",
    "#     titanic_lab directory in HDFS.\n",
    "!hdfs dfs -put -f titanic.csv /titanic_lab/\n",
    "#!/usr/bin/env python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Use chmod command to change the permissions of the Titanic dataset\n",
    "#     file to 777 (full permissions for all).\n",
    "!hdfs dfs -chmod 777 /titanic_lab/titanic.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Use-cat to display the first 20 lines of the Titanic dataset stored\n",
    "#     in HDFS.\n",
    "!hdfs dfs -cat /titanic_lab/titanic.csv | head -n 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15- Move the processed output file from titanic_lab to a new directory\n",
    "# in HDFS called titanic_results using hdfs dfs -mv.\n",
    "!hdfs dfs -mkdir -p /titanic_results\n",
    "!hdfs dfs -mv /titanic_lab/titanic.csv /titanic_results/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
